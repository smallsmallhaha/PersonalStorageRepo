# Ceres-solver usage
使用ceres-solver的步骤是: 定义CostFunction -> 将CostFunction的实例加入ceres::Problem(优化问题) -> 求解。
注意: 对于复杂方程请给出较好的初值，方便ceres-solver进行迭代。


# CostFunction & Problem::AddResidualBlock
## AutoDiffCostFunction
在明确知道非线性方程的数据表达式时，可以使用AutoDiffCostFunction自动求导，类的签名如下:
```cpp
// A cost function which computes the derivative of the cost with respect to
// the parameters (a.k.a. the jacobian) using an autodifferentiation framework.
// The first template argument is the functor object, described in the header
// comment. The second argument is the dimension of the residual (or
// ceres::DYNAMIC to indicate it will be set at runtime), and subsequent
// arguments describe the size of the Nth parameter, one per parameter.
//
// The constructors take ownership of the cost functor.
//
// If the number of residuals (argument kNumResiduals below) is
// ceres::DYNAMIC, then the two-argument constructor must be used. The
// second constructor takes a number of residuals (in addition to the
// templated number of residuals). This allows for varying the number
// of residuals for a single autodiff cost function at runtime.
template <typename CostFunctor,
          int kNumResiduals,  // Number of residuals, or ceres::DYNAMIC.
          int N0,       // Number of parameters in block 0.
          int N1 = 0,   // Number of parameters in block 1.
          int N2 = 0,   // Number of parameters in block 2.
          int N3 = 0,   // Number of parameters in block 3.
          int N4 = 0,   // Number of parameters in block 4.
          int N5 = 0,   // Number of parameters in block 5.
          int N6 = 0,   // Number of parameters in block 6.
          int N7 = 0,   // Number of parameters in block 7.
          int N8 = 0,   // Number of parameters in block 8.
          int N9 = 0>   // Number of parameters in block 9.
class AutoDiffCostFunction : public SizedCostFunction<kNumResiduals,
                                                      N0, N1, N2, N3, N4,
                                                      N5, N6, N7, N8, N9>
```
## NumericDiffCostFunction
有些方程难以通过具体的表达式表示(譬如方程中调用到第三方库的函数)，此时可以使用NumericDiffCostFunction，类的签名如下:
```cpp
template <typename CostFunctor,
          NumericDiffMethodType method = CENTRAL,
          int kNumResiduals = 0,  // Number of residuals, or ceres::DYNAMIC
          int N0 = 0,   // Number of parameters in block 0.
          int N1 = 0,   // Number of parameters in block 1.
          int N2 = 0,   // Number of parameters in block 2.
          int N3 = 0,   // Number of parameters in block 3.
          int N4 = 0,   // Number of parameters in block 4.
          int N5 = 0,   // Number of parameters in block 5.
          int N6 = 0,   // Number of parameters in block 6.
          int N7 = 0,   // Number of parameters in block 7.
          int N8 = 0,   // Number of parameters in block 8.
          int N9 = 0>   // Number of parameters in block 9.
class NumericDiffCostFunction
    : public SizedCostFunction<kNumResiduals,
                               N0, N1, N2, N3, N4,
                               N5, N6, N7, N8, N9>
```
## SizedCostFunction
```cpp
template<int kNumResiduals,
         int N0 = 0, int N1 = 0, int N2 = 0, int N3 = 0, int N4 = 0,
         int N5 = 0, int N6 = 0, int N7 = 0, int N8 = 0, int N9 = 0>
class SizedCostFunction
// jacobians[i][r*parameter_block_size_[i] + c] = d residual[r] / d parameters[i][c]
// 注: 雅克比矩阵方程中的i为参数块的序号，r为残差序号，c为参数块中的参数序号。
```
## Problem::AddResidualBlock
```cpp
ResidualBlockId AddResidualBlock(CostFunction* cost_function,
                                   LossFunction* loss_function,
                                   double* x0, double* x1, double* x2);
// 参数向量x0,x1,x2的维数必须与cost_function中的模板参数N0,N1,N2一一对应
```
## Tips
若AutoDiffCostFunction或NumericDiffCostFunction中的模板参数kNumResiduals的值为ceres::DYNAMIC，则使用者必须在构造函数中指定残差方程的个数num_residuals！


# Reference
## AutoDiffCostFunction
```
Create CostFunctions as needed by the least squares framework, with
Jacobians computed via automatic differentiation. For more
information on automatic differentation, see the wikipedia article
at http://en.wikipedia.org/wiki/Automatic_differentiation

To get an auto differentiated cost function, you must define a class with a
templated operator() (a functor) that computes the cost function in terms of
the template parameter T. The autodiff framework substitutes appropriate
"jet" objects for T in order to compute the derivative when necessary, but
this is hidden, and you should write the function as if T were a scalar type
(e.g. a double-precision floating point number).

The function must write the computed value in the last argument
(the only non-const one) and return true to indicate
success. Please see cost_function.h for details on how the return
value maybe used to impose simple constraints on the parameter
block.

For example, consider a scalar error e = k - x'y, where both x and y are
two-dimensional column vector parameters, the prime sign indicates
transposition, and k is a constant. The form of this error, which is the
difference between a constant and an expression, is a common pattern in least
squares problems. For example, the value x'y might be the model expectation
for a series of measurements, where there is an instance of the cost function
for each measurement k.

The actual cost added to the total problem is e^2, or (k - x'k)^2; however,
the squaring is implicitly done by the optimization framework.

To write an auto-differentiable cost function for the above model, first
define the object

  class MyScalarCostFunctor {
    MyScalarCostFunctor(double k): k_(k) {}

    template <typename T>
    bool operator()(const T* const x , const T* const y, T* e) const {
      e[0] = T(k_) - x[0] * y[0] + x[1] * y[1];
      return true;
    }

   private:
    double k_;
  };

Note that in the declaration of operator() the input parameters x and y come
first, and are passed as const pointers to arrays of T. If there were three
input parameters, then the third input parameter would come after y. The
output is always the last parameter, and is also a pointer to an array. In
the example above, e is a scalar, so only e[0] is set.

Then given this class definition, the auto differentiated cost function for
it can be constructed as follows.

  CostFunction* cost_function
      = new AutoDiffCostFunction<MyScalarCostFunctor, 1, 2, 2>(
           new MyScalarCostFunctor(1.0));             ^  ^  ^
                                                      |  |  |
                           Dimension of residual -----+  |  |
                           Dimension of x ---------------+  |
                           Dimension of y ------------------+

In this example, there is usually an instance for each measumerent of k.

In the instantiation above, the template parameters following
"MyScalarCostFunctor", "1, 2, 2", describe the functor as computing a
1-dimensional output from two arguments, both 2-dimensional.

AutoDiffCostFunction also supports cost functions with a
runtime-determined number of residuals. For example:

  CostFunction* cost_function
      = new AutoDiffCostFunction<MyScalarCostFunctor, DYNAMIC, 2, 2>(
          new CostFunctorWithDynamicNumResiduals(1.0),   ^     ^  ^
          runtime_number_of_residuals); <----+           |     |  |
                                             |           |     |  |
                                             |           |     |  |
            Actual number of residuals ------+           |     |  |
            Indicate dynamic number of residuals --------+     |  |
            Dimension of x ------------------------------------+  |
            Dimension of y ---------------------------------------+

The framework can currently accommodate cost functions of up to 10
independent variables, and there is no limit on the dimensionality
of each of them.

WARNING #1: Since the functor will get instantiated with different types for
T, you must to convert from other numeric types to T before mixing
computations with other variables of type T. In the example above, this is
seen where instead of using k_ directly, k_ is wrapped with T(k_).

WARNING #2: A common beginner's error when first using autodiff cost
functions is to get the sizing wrong. In particular, there is a tendency to
set the template parameters to (dimension of residual, number of parameters)
instead of passing a dimension parameter for *every parameter*. In the
example above, that would be <MyScalarCostFunctor, 1, 2>, which is missing
the last '2' argument. Please be careful when setting the size parameters.
```
## NumericDiffCostFunction
```
Create CostFunctions as needed by the least squares framework with jacobians
computed via numeric (a.k.a. finite) differentiation. For more details see
http://en.wikipedia.org/wiki/Numerical_differentiation.

To get an numerically differentiated cost function, you must define
a class with a operator() (a functor) that computes the residuals.

The function must write the computed value in the last argument
(the only non-const one) and return true to indicate success.
Please see cost_function.h for details on how the return value
maybe used to impose simple constraints on the parameter block.

For example, consider a scalar error e = k - x'y, where both x and y are
two-dimensional column vector parameters, the prime sign indicates
transposition, and k is a constant. The form of this error, which is the
difference between a constant and an expression, is a common pattern in least
squares problems. For example, the value x'y might be the model expectation
for a series of measurements, where there is an instance of the cost function
for each measurement k.

The actual cost added to the total problem is e^2, or (k - x'k)^2; however,
the squaring is implicitly done by the optimization framework.

To write an numerically-differentiable cost function for the above model, first
define the object

  class MyScalarCostFunctor {
    MyScalarCostFunctor(double k): k_(k) {}

    bool operator()(const double* const x,
                    const double* const y,
                    double* residuals) const {
      residuals[0] = k_ - x[0] * y[0] + x[1] * y[1];
      return true;
    }

   private:
    double k_;
  };

Note that in the declaration of operator() the input parameters x
and y come first, and are passed as const pointers to arrays of
doubles. If there were three input parameters, then the third input
parameter would come after y. The output is always the last
parameter, and is also a pointer to an array. In the example above,
the residual is a scalar, so only residuals[0] is set.

Then given this class definition, the numerically differentiated
cost function with central differences used for computing the
derivative can be constructed as follows.

  CostFunction* cost_function
      = new NumericDiffCostFunction<MyScalarCostFunctor, CENTRAL, 1, 2, 2>(
          new MyScalarCostFunctor(1.0));                    ^     ^  ^  ^
                                                            |     |  |  |
                                Finite Differencing Scheme -+     |  |  |
                                Dimension of residual ------------+  |  |
                                Dimension of x ----------------------+  |
                                Dimension of y -------------------------+

In this example, there is usually an instance for each measurement of k.

In the instantiation above, the template parameters following
"MyScalarCostFunctor", "1, 2, 2", describe the functor as computing
a 1-dimensional output from two arguments, both 2-dimensional.

NumericDiffCostFunction also supports cost functions with a
runtime-determined number of residuals. For example:

  CostFunction* cost_function
      = new NumericDiffCostFunction<MyScalarCostFunctor, CENTRAL, DYNAMIC, 2, 2>(
          new CostFunctorWithDynamicNumResiduals(1.0),               ^     ^  ^
          TAKE_OWNERSHIP,                                            |     |  |
          runtime_number_of_residuals); <----+                       |     |  |
                                             |                       |     |  |
                                             |                       |     |  |
            Actual number of residuals ------+                       |     |  |
            Indicate dynamic number of residuals --------------------+     |  |
            Dimension of x ------------------------------------------------+  |
            Dimension of y ---------------------------------------------------+

The framework can currently accommodate cost functions of up to 10
independent variables, and there is no limit on the dimensionality
of each of them.

The central difference method is considerably more accurate at the cost of
twice as many function evaluations than forward difference. Consider using
central differences begin with, and only after that works, trying forward
difference to improve performance.

WARNING #1: A common beginner's error when first using
NumericDiffCostFunction is to get the sizing wrong. In particular,
there is a tendency to set the template parameters to (dimension of
residual, number of parameters) instead of passing a dimension
parameter for *every parameter*. In the example above, that would
be <MyScalarCostFunctor, 1, 2>, which is missing the last '2'
argument. Please be careful when setting the size parameters.

/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////

ALTERNATE INTERFACE

For a variety of reasons, including compatibility with legacy code,
NumericDiffCostFunction can also take CostFunction objects as
input. The following describes how.

To get a numerically differentiated cost function, define a
subclass of CostFunction such that the Evaluate() function ignores
the jacobian parameter. The numeric differentiation wrapper will
fill in the jacobian parameter if necessary by repeatedly calling
the Evaluate() function with small changes to the appropriate
parameters, and computing the slope. For performance, the numeric
differentiation wrapper class is templated on the concrete cost
function, even though it could be implemented only in terms of the
virtual CostFunction interface.

The numerically differentiated version of a cost function for a cost function
can be constructed as follows:

  CostFunction* cost_function
      = new NumericDiffCostFunction<MyCostFunction, CENTRAL, 1, 4, 8>(
          new MyCostFunction(...), TAKE_OWNERSHIP);

where MyCostFunction has 1 residual and 2 parameter blocks with sizes 4 and 8
respectively. Look at the tests for a more detailed example.

TODO(keir): Characterize accuracy; mention pitfalls; provide alternatives.
```
## SizedCostFunction
```cpp
bool CostFunction::Evaluate(double const *const *parameters, double *residuals, double **jacobians);
```
```
Compute the residual vector and the Jacobian matrices.

parameters is an array of arrays of size CostFunction::parameter_block_sizes_.size() and parameters[i] is an array of size parameter_block_sizes_[i] that contains the ith parameter block that the CostFunction depends on.

parameters is never NULL.

residuals is an array of size num_residuals_.

residuals is never NULL.

jacobians is an array of arrays of size CostFunction::parameter_block_sizes_.size().

If jacobians is NULL, the user is only expected to compute the residuals.

jacobians[i] is a row-major array of size num_residuals x parameter_block_sizes_[i].

If jacobians[i] is not NULL, the user is required to compute the Jacobian of the residual vector with respect to parameters[i] and store it in this array, i.e.

jacobians[i][r*parameter_block_size_[i] + c] = d residual[r] / d parameters[i][c]

If jacobians[i] is NULL, then this computation can be skipped. This is the case when the corresponding parameter block is marked constant.

The return value indicates whether the computation of the residuals and/or jacobians was successful or not. This can be used to communicate numerical failures in Jacobian computations for instance.
```
